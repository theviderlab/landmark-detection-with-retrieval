{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7797a180-6441-4503-920f-0b2d759072dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Notebook Snippet: Verificar equivalencia de backbones\n",
    "# ----------------------------------------------\n",
    "\n",
    "from image_retrieval.backbones.cvnet.cvnet_backbone import CVNetBackbone    # Ruta de ejemplo al código antiguo\n",
    "from landmark_detection.resnet import ResNet              # Ruta de ejemplo al código nuevo\n",
    "\n",
    "# Parámetros (ajústalos según tu configuración real):\n",
    "RESNET_DEPTH    = 50\n",
    "REDUCTION_DIM   = 2048\n",
    "OLD_PRETRAINED_PATH = \"image_retrieval/backbones/cvnet/CVPR2022_CVNet_R50.pyth\"  # peso que usas en el nuevo código\n",
    "NEW_PRETRAINED_PATH = \"landmark_detection/CVNet_50_2048.pth\"  # peso que usas en el nuevo código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eecec6bd-831b-4eb6-935b-68a44f74a9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVNetBackbone(\n",
       "  (model): CVNet_Rerank(\n",
       "    (encoder_q): ResNet(\n",
       "      (stem): ResStemIN(\n",
       "        (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (s1): ResStage(\n",
       "        (b1): ResBlock(\n",
       "          (proj): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b2): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b3): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (s2): ResStage(\n",
       "        (b1): ResBlock(\n",
       "          (proj): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b2): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b3): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b4): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (s3): ResStage(\n",
       "        (b1): ResBlock(\n",
       "          (proj): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b2): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b3): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b4): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b5): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b6): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (s4): ResStage(\n",
       "        (b1): ResBlock(\n",
       "          (proj): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b2): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (b3): ResBlock(\n",
       "          (f): BottleneckTransform(\n",
       "            (a): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (a_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (a_relu): ReLU(inplace=True)\n",
       "            (b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (b_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (b_relu): ReLU(inplace=True)\n",
       "            (c): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (c_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (head): GlobalHead(\n",
       "        (pool): GeneralizedMeanPoolingP(Parameter containing:\n",
       "        tensor([1.9281], requires_grad=True), output_size=1)\n",
       "        (fc): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (conv2ds): ModuleList(\n",
       "      (0-2): 3 x Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (cv_learner): CVLearner(\n",
       "      (block1): Sequential(\n",
       "        (0): CenterPivotConv4d(\n",
       "          (conv1): Conv2d(9, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "          (conv2): Conv2d(9, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "        )\n",
       "        (1): GroupNorm(4, 16, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (block2): Sequential(\n",
       "        (0): CenterPivotConv4d(\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): GroupNorm(4, 16, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): CenterPivotConv4d(\n",
       "          (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "        (4): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3): Sequential(\n",
       "        (0): CenterPivotConv4d(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): CenterPivotConv4d(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (4): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): CenterPivotConv4d(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "        (7): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "      )\n",
       "      (block4): Sequential(\n",
       "        (0): CenterPivotConv4d(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): CenterPivotConv4d(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (4): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): CenterPivotConv4d(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (7): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Old backbone\n",
    "old_backbone = CVNetBackbone(depth=RESNET_DEPTH, reduction_dim=REDUCTION_DIM, pretrained_weights=OLD_PRETRAINED_PATH)\n",
    "old_backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "497508a0-f422-4b6c-a30c-25b339854c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (stem): ResStemIN(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (s1): ResStage(\n",
       "    (b1): ResBlock(\n",
       "      (proj): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s2): ResStage(\n",
       "    (b1): ResBlock(\n",
       "      (proj): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s3): ResStage(\n",
       "    (b1): ResBlock(\n",
       "      (proj): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b5): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b6): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (s4): ResStage(\n",
       "    (b1): ResBlock(\n",
       "      (proj): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): ResBlock(\n",
       "      (f): BottleneckTransform(\n",
       "        (a): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (a_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (a_relu): ReLU(inplace=True)\n",
       "        (b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (b_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (b_relu): ReLU(inplace=True)\n",
       "        (c): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (c_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (head): GlobalHead(\n",
       "    (pool): GeneralizedMeanPoolingP(Parameter containing:\n",
       "    tensor([1.9281], requires_grad=True), output_size=1)\n",
       "    (fc): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New backbone\n",
    "new_backbone = ResNet(RESNET_DEPTH, REDUCTION_DIM)\n",
    "# Precisamos cargar el mismo state_dict que el antiguo:\n",
    "checkpoint = torch.load(NEW_PRETRAINED_PATH, map_location=\"cpu\")\n",
    "state_dict = checkpoint.get(\"state_dict\", checkpoint)\n",
    "new_backbone.load_state_dict(state_dict, strict=True)\n",
    "new_backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc15bce-14d7-4262-bf48-1fab13bea035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Generar una imagen de prueba aleatoria:\n",
    "#    Usa un tamaño típico (p.ej. 1 imagen de 224×224).\n",
    "H, W = 224, 224\n",
    "batch_size = 2  # puedes usar 1 o más para verificar en batch\n",
    "\n",
    "# Imagen en numpy NHWC, valores en [0,1]\n",
    "img_np = (np.random.rand(batch_size, H, W, 3)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ec0585-0a40-45e5-9f4b-317cc034803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Pasar por ambos backbones:\n",
    "\n",
    "# --- Old backbone: produce numpy NHWC (n, h, w, C) ---\n",
    "fm_old_nhwc = old_backbone.predict(img_np)  # shape: (batch_size, h, w, C)\n",
    "\n",
    "# Convertir a Tensor NCHW para comparar:\n",
    "fm_old = torch.from_numpy(fm_old_nhwc).permute(0, 3, 1, 2)  # (batch_size, C, h, w)\n",
    "\n",
    "# --- New backbone: acepta NCHW torch.Tensor ---\n",
    "# Convertir img_np a torch.Tensor NCHW\n",
    "img_tensor = torch.from_numpy(img_np).permute(0, 3, 1, 2)  # (batch_size, 3, H, W)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fm_new = new_backbone(img_tensor)  # (batch_size, 2048, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb36ffa-e011-4079-be79-18d7c5d751db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape FM old (NCHW): torch.Size([2, 2048, 7, 7])\n",
      "Shape FM new (NCHW): torch.Size([2, 2048, 7, 7])\n",
      "¿Outputs iguales (tol=1e-5)? True\n",
      "Diferencia máxima entre tensores: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# 5) Comparar resultados:\n",
    "\n",
    "print(\"Shape FM old (NCHW):\", fm_old.shape)\n",
    "print(\"Shape FM new (NCHW):\", fm_new.shape)\n",
    "\n",
    "# Comprobamos que sean casi iguales numéricamente:\n",
    "are_close = torch.allclose(fm_old, fm_new, atol=1e-5)\n",
    "max_diff = (fm_old - fm_new).abs().max().item()\n",
    "\n",
    "print(f\"¿Outputs iguales (tol=1e-5)? {are_close}\")\n",
    "print(f\"Diferencia máxima entre tensores: {max_diff:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61611afa-9a5e-42ce-b98b-ea85be251c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from image_retrieval.global_features.pooling import Pooling\n",
    "from landmark_detection.pooling import SuperGlobalExtractor, RGEM_Batch, GEMp_Batch, SGEM_Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cff2ee0-de9c-4d39-b8e3-9c68472f146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de prueba\n",
    "batch_size = 2\n",
    "aug = 3\n",
    "N = batch_size * aug\n",
    "C = 2048\n",
    "H = 7\n",
    "W = 7\n",
    "\n",
    "# 1) Generar feature maps aleatorios en formato NHWC para el código antiguo\n",
    "fm_nhwc  = np.random.rand(N, H, W, C).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b366d28a-5dd6-46bb-8101-e620fad0a4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGEM: máximo diff = 5.9604645e-08\n"
     ]
    }
   ],
   "source": [
    "# 1a) Salida RGEM antiguo (TF/NumPy):\n",
    "pool_rgem = Pooling(method=\"rgem\", method_params={\"pr\": 2.5, \"size\": 5})\n",
    "rgem_old = pool_rgem(fm_nhwc)           # (N, H, W, C)\n",
    "\n",
    "# 1b) Salida RGEM nuevo (PyTorch):\n",
    "rgem_new_mod = RGEM_Batch(pr=2.5, size=5)\n",
    "# convertir a NCHW tensor\n",
    "fm_nchw = torch.from_numpy(fm_nhwc).permute(0, 3, 1, 2)\n",
    "with torch.no_grad():\n",
    "    rgem_new = rgem_new_mod(fm_nchw).permute(0, 2, 3, 1).cpu().numpy()  # (N, H, W, C)\n",
    "\n",
    "print(\"RGEM: máximo diff =\", np.max(np.abs(rgem_old - rgem_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53551fc3-7b1e-466a-8741-03a320e116cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeM: máximo diff = 2.9802322e-08\n"
     ]
    }
   ],
   "source": [
    "# —— 2) GeM —— \n",
    "\n",
    "# 2a) Salida GeM antiguo: entrada = rgem_old (NHWC)\n",
    "pool_gem = Pooling(method=\"gem\", method_params={\"p\": 4.6, \"eps\": 1e-8})\n",
    "gem_old = pool_gem(rgem_new)  # NumPy array shape (N, C)\n",
    "\n",
    "# 2b) Salida GeM nuevo: entrada = rgem_new (torch tensor NCHW)\n",
    "# ya tenemos rgem_new de forma (N, C, H, W)\n",
    "gem_new_mod = GEMp_Batch(p=4.6, eps=1e-8)\n",
    "# convertir a NCHW tensor\n",
    "rgem_old = torch.from_numpy(rgem_new).permute(0, 3, 1, 2)\n",
    "with torch.no_grad():\n",
    "    gem_new = gem_new_mod(rgem_old)  # (N, C)\n",
    "gem_new_np = gem_new.cpu().numpy()  # a NumPy\n",
    "\n",
    "print(\"GeM: máximo diff =\", np.max(np.abs(gem_old - gem_new_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e6f9490-abd3-4e50-bcc5-905d10a6f1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGEM: máximo diff = 3.6282465e-05\n"
     ]
    }
   ],
   "source": [
    "# 3a) Normalizar antiguo + SGEM antiguo\n",
    "pooled_norm_old = tf.linalg.l2_normalize(tf.convert_to_tensor(gem_new_np), axis=1).numpy()  # (N, C)\n",
    "sgem_old = pool_rgem.sgem_fusion(\n",
    "    descriptors=pooled_norm_old,\n",
    "    aug=aug,\n",
    "    mode=\"lp\",\n",
    "    p=5.0,\n",
    "    eps=1e-8\n",
    ")  # (batch_size, C)\n",
    "\n",
    "# 3b) Normalizar nuevo + SGEM nuevo\n",
    "gem_new_np = torch.from_numpy(gem_new_np)\n",
    "pooled_norm_new = torch.nn.functional.normalize(gem_new_np, p=2, dim=1)  # (N, C)\n",
    "sgem_new_mod = SGEM_Batch(ps=5.0, infinity=False, eps=1e-8)\n",
    "with torch.no_grad():\n",
    "    sgem_new = sgem_new_mod(pooled_norm_new, aug=aug).cpu().numpy()  # (batch_size, C)\n",
    "\n",
    "print(\"SGEM: máximo diff =\", np.max(np.abs(sgem_old - sgem_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14993e46-c194-4bd6-902b-8112c867e9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Código antiguo (TF + NumPy) =====\n",
    "feature_maps_nhwc  = np.random.rand(N, H, W, C).astype(np.float32)\n",
    "# Instanciar pooling con RGEM y GeM\n",
    "use_rgem = True\n",
    "rgem_params = {'pr': 2.5, 'size': 5}\n",
    "pool_rgem = Pooling(method=\"rgem\", method_params=rgem_params)\n",
    "pool_gem = Pooling(method=\"gem\", method_params={'p': 4.6, 'eps': 1e-8})\n",
    "\n",
    "# 1a) Regional-GeM sobre NHWC\n",
    "if use_rgem:\n",
    "    rgem_out = pool_rgem(feature_maps_nhwc)  # (N, H, W, C)\n",
    "else:\n",
    "    rgem_out = feature_maps_nhwc\n",
    "\n",
    "# 1b) GeM global pooling: de (N, H, W, C) a (N, C)\n",
    "pooled_old = pool_gem(rgem_out)  # NumPy array shape (N, C)\n",
    "\n",
    "# 1c) Normalización L2 fila a fila\n",
    "pooled_tf = tf.convert_to_tensor(pooled_old, dtype=tf.float32)\n",
    "pooled_norm = tf.linalg.l2_normalize(pooled_tf, axis=1).numpy()  # (N, C)\n",
    "\n",
    "# 1d) SGEM_fusion (Scale-GeM) para fusionar cada grupo de 'aug' vectores\n",
    "pooling_for_sgem = pool_rgem  # Instancia de Pooling tiene el método sgem_fusion\n",
    "old_descriptors = pooling_for_sgem.sgem_fusion(\n",
    "    descriptors=pooled_norm,\n",
    "    aug=aug,\n",
    "    mode=\"lp\",\n",
    "    p=10.0,\n",
    "    eps=1e-8\n",
    ")  # NumPy array shape (batch_size, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "322b648e-aa54-45c6-bd6d-97cd7b7aa538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Código nuevo (PyTorch) =====\n",
    "\n",
    "# Convertir feature_maps_nhwc a formato NCHW torch.Tensor\n",
    "feature_maps_nchw = torch.from_numpy(feature_maps_nhwc).permute(0, 3, 1, 2)  # (N, C, H, W)\n",
    "\n",
    "# Instanciar el extractor PyTorch\n",
    "new_extractor = SuperGlobalExtractor(\n",
    "    rgem_pr=2.5, rgem_size=5,\n",
    "    gem_p=4.6,\n",
    "    sgem_ps=10.0,\n",
    "    sgem_infinity=False,\n",
    "    eps=1e-8\n",
    ").eval()\n",
    "\n",
    "# 2) Obtener los descriptores con el código nuevo\n",
    "with torch.no_grad():\n",
    "    new_descriptors = new_extractor(feature_maps_nchw, aug=aug)  # (batch_size, C)\n",
    "new_descriptors_np = new_descriptors.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03660b75-fec9-4188-a1b5-cafcb3fe7d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape old descriptors: (2, 2048)\n",
      "Shape new descriptors: (2, 2048)\n",
      "¿Descriptors iguales? False\n",
      "Diferencia máxima: 0.000031\n"
     ]
    }
   ],
   "source": [
    "# ===== Comparación entre viejo y nuevo =====\n",
    "\n",
    "print(\"Shape old descriptors:\", old_descriptors.shape)\n",
    "print(\"Shape new descriptors:\", new_descriptors_np.shape)\n",
    "\n",
    "# Comprobar que sean cercanos numéricamente\n",
    "are_close = np.allclose(old_descriptors, new_descriptors_np, atol=1e-5)\n",
    "max_diff = np.max(np.abs(old_descriptors - new_descriptors_np))\n",
    "\n",
    "print(f\"¿Descriptors iguales? {are_close}\")\n",
    "print(f\"Diferencia máxima: {max_diff:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eadf483b-5b7f-4fc0-b8a7-09195183a776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0217317 , 0.02197091, 0.02226226, ..., 0.02341955, 0.02229463,\n",
       "        0.02066084],\n",
       "       [0.02271119, 0.02245686, 0.02252023, ..., 0.0227776 , 0.02292699,\n",
       "        0.02339281]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1a6048e-fb2b-4ee1-887e-863ec44a1745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0217317 , 0.02197091, 0.02226226, ..., 0.02341955, 0.02229463,\n",
       "        0.02066084],\n",
       "       [0.02273296, 0.0224573 , 0.02253044, ..., 0.02280346, 0.02294248,\n",
       "        0.02340364]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_descriptors_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58a37239-4cfc-4c70-8c4b-6565b67259ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Running SGEM Debug ==\n",
      "reshaped (B, aug, d):\n",
      "tensor([[[0.0223, 0.0236, 0.0222,  ..., 0.0231, 0.0221, 0.0235],\n",
      "         [0.0210, 0.0228, 0.0238,  ..., 0.0227, 0.0232, 0.0229],\n",
      "         [0.0223, 0.0221, 0.0221,  ..., 0.0222, 0.0207, 0.0220]],\n",
      "\n",
      "        [[0.0228, 0.0232, 0.0227,  ..., 0.0230, 0.0233, 0.0230],\n",
      "         [0.0210, 0.0235, 0.0213,  ..., 0.0216, 0.0220, 0.0229],\n",
      "         [0.0214, 0.0198, 0.0220,  ..., 0.0238, 0.0217, 0.0220]]],\n",
      "       dtype=torch.float64)\n",
      "gamma (scalar): 0.017812207341194153\n",
      "centered (reshaped - gamma):\n",
      "tensor([[[0.0045, 0.0058, 0.0044,  ..., 0.0053, 0.0043, 0.0057],\n",
      "         [0.0032, 0.0050, 0.0060,  ..., 0.0049, 0.0054, 0.0051],\n",
      "         [0.0044, 0.0042, 0.0043,  ..., 0.0044, 0.0029, 0.0042]],\n",
      "\n",
      "        [[0.0050, 0.0054, 0.0049,  ..., 0.0051, 0.0055, 0.0052],\n",
      "         [0.0032, 0.0056, 0.0035,  ..., 0.0038, 0.0042, 0.0051],\n",
      "         [0.0036, 0.0020, 0.0042,  ..., 0.0060, 0.0039, 0.0041]]],\n",
      "       dtype=torch.float64)\n",
      "x_pow (clamped ^ 10.0):\n",
      "tensor([[[3.5054e-24, 3.9657e-23, 2.8544e-24,  ..., 1.8717e-23,\n",
      "          2.0000e-24, 3.6288e-23],\n",
      "         [9.9829e-26, 9.4451e-24, 5.5905e-23,  ..., 7.9361e-24,\n",
      "          2.1583e-23, 1.2344e-23],\n",
      "         [3.0287e-24, 1.8865e-24, 2.1299e-24,  ..., 2.5866e-24,\n",
      "          3.7162e-26, 1.7545e-24]],\n",
      "\n",
      "        [[9.8699e-24, 2.1889e-23, 8.5861e-24,  ..., 1.2997e-23,\n",
      "          2.5048e-23, 1.3474e-23],\n",
      "         [1.0029e-25, 3.2443e-23, 3.0652e-25,  ..., 6.2927e-25,\n",
      "          1.5483e-24, 1.2760e-23],\n",
      "         [3.5875e-25, 1.1729e-27, 1.6873e-24,  ..., 5.8846e-23,\n",
      "          8.2199e-25, 1.5122e-24]]], dtype=torch.float64)\n",
      "pooled (mean over aug):\n",
      "tensor([[2.2113e-24, 1.6996e-23, 2.0296e-23,  ..., 9.7466e-24, 7.8734e-24,\n",
      "         1.6796e-23],\n",
      "        [3.4430e-24, 1.8111e-23, 3.5266e-24,  ..., 2.4157e-23, 9.1396e-24,\n",
      "         9.2486e-24]], dtype=torch.float64)\n",
      "root (pooled ^ (1/10.0)): \n",
      "tensor([[0.0043, 0.0053, 0.0054,  ..., 0.0050, 0.0049, 0.0053],\n",
      "        [0.0045, 0.0053, 0.0045,  ..., 0.0055, 0.0050, 0.0050]],\n",
      "       dtype=torch.float64)\n",
      "output SGEM^p (root + gamma):\n",
      "tensor([[0.0221, 0.0231, 0.0232,  ..., 0.0228, 0.0227, 0.0231],\n",
      "        [0.0223, 0.0231, 0.0223,  ..., 0.0233, 0.0228, 0.0228]],\n",
      "       dtype=torch.float64)\n",
      "Final output:\n",
      "tensor([[0.0221, 0.0231, 0.0232,  ..., 0.0228, 0.0227, 0.0231],\n",
      "        [0.0223, 0.0231, 0.0223,  ..., 0.0233, 0.0228, 0.0228]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class SGEM_Debug(nn.Module):\n",
    "    \"\"\"\n",
    "    SGEM with debug prints to trace intermediate computations.\n",
    "    \"\"\"\n",
    "    def __init__(self, ps=10.0, infinity=False, eps=1e-8):\n",
    "        super(SGEM_Debug, self).__init__()\n",
    "        self.ps = ps\n",
    "        self.infinity = infinity\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x: torch.Tensor, aug: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): Input descriptors, shape (N, d) where N = batch_size * aug\n",
    "            aug (int): Number of augmentations (scales) per sample\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Fused descriptors, shape (batch_size, d)\n",
    "        \"\"\"\n",
    "        N, d = x.shape\n",
    "        if N % aug != 0:\n",
    "            raise ValueError(f\"N={N} not divisible by aug={aug}\")\n",
    "        B = N // aug  # batch_size\n",
    "\n",
    "        # 1) Reshape\n",
    "        reshaped = x.view(B, aug, d)  # (B, aug, d)\n",
    "        print(\"reshaped (B, aug, d):\")\n",
    "        print(reshaped)\n",
    "\n",
    "        if self.infinity:\n",
    "            # SGEM∞: normalize each vector and max over aug\n",
    "            norms = torch.norm(reshaped, p=2, dim=2, keepdim=True) + self.eps  # (B, aug, 1)\n",
    "            print(\"norms (before normalization):\")\n",
    "            print(norms)\n",
    "            normalized = reshaped / norms  # (B, aug, d)\n",
    "            print(\"normalized (B, aug, d):\")\n",
    "            print(normalized)\n",
    "            output = normalized.max(dim=1)[0]  # (B, d)\n",
    "            print(\"output SGEM∞ (B, d):\")\n",
    "            print(output)\n",
    "        else:\n",
    "            # SGEM^p: gamma = minimum over whole tensor (scalar)\n",
    "            gamma = reshaped.min()  # scalar\n",
    "            print(\"gamma (scalar):\", gamma.item())\n",
    "\n",
    "            # Center\n",
    "            centered = reshaped - gamma  # (B, aug, d)\n",
    "            print(\"centered (reshaped - gamma):\")\n",
    "            print(centered)\n",
    "\n",
    "            # Power\n",
    "            x_pow = centered.pow(self.ps)  # (B, aug, d)\n",
    "            print(f\"x_pow (clamped ^ {self.ps}):\")\n",
    "            print(x_pow)\n",
    "\n",
    "            # Pool (mean over aug)\n",
    "            pooled = x_pow.mean(dim=1)  # (B, d)\n",
    "            print(\"pooled (mean over aug):\")\n",
    "            print(pooled)\n",
    "\n",
    "            # Root and add gamma\n",
    "            root = pooled.pow(1.0 / self.ps)  # (B, d)\n",
    "            print(f\"root (pooled ^ (1/{self.ps})): \")\n",
    "            print(root)\n",
    "\n",
    "            output = root + gamma  # (B, d)\n",
    "            print(\"output SGEM^p (root + gamma):\")\n",
    "            print(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "aug = 3\n",
    "pooled_norm_new_dbl = pooled_norm_new.double()\n",
    "sgem_debug = SGEM_Debug(ps=10.0, infinity=False, eps=1e-8)\n",
    "print(\"== Running SGEM Debug ==\")\n",
    "sgem_output = sgem_debug(pooled_norm_new_dbl, aug=aug)\n",
    "print(\"Final output:\")\n",
    "print(sgem_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a972ad65-0337-4c63-a6d0-f811bf8b919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Versión NumPy de sgem_fusion con prints para debug\n",
    "def sgem_fusion_numpy(descriptors, aug=1, p=10.0, eps=1e-8):\n",
    "    \"\"\"\n",
    "    descriptors: numpy array shape (n, d), n = batch_size * aug\n",
    "    \"\"\"\n",
    "    n, d = descriptors.shape\n",
    "    assert n % aug == 0, \"n debe ser divisible por aug\"\n",
    "    batch_size = n // aug\n",
    "\n",
    "    # Reorganizar: (batch_size, aug, d)\n",
    "    reshaped = descriptors.reshape(batch_size, aug, d)\n",
    "    print(\"NumPy - reshaped (batch_size, aug, d):\")\n",
    "    print(reshaped)\n",
    "\n",
    "    # Modo LP\n",
    "    gamma = np.min(reshaped)\n",
    "    print(\"NumPy - gamma (scalar):\", gamma)\n",
    "\n",
    "    centered = reshaped - gamma\n",
    "    print(\"NumPy - centered (reshaped - gamma):\")\n",
    "    print(centered)\n",
    "\n",
    "    x_pow = np.power(centered, p)\n",
    "    print(f\"NumPy - x_pow (centered ^ {p}):\")\n",
    "    print(x_pow)\n",
    "\n",
    "    pooled = np.mean(x_pow, axis=1)  # (batch_size, d)\n",
    "    print(\"NumPy - pooled (mean over aug):\")\n",
    "    print(pooled)\n",
    "\n",
    "    root = np.power(pooled, 1.0 / p)\n",
    "    print(f\"NumPy - root (pooled ^ (1/{p})): \")\n",
    "    print(root)\n",
    "\n",
    "    output = root + gamma  # (batch_size, d)\n",
    "    print(\"NumPy - output (root + gamma):\")\n",
    "    print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "862d48d4-e2f7-465e-90e2-49fa17741bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NumPy SGEM Debug ===\n",
      "NumPy - reshaped (batch_size, aug, d):\n",
      "[[[0.02232529 0.02356438 0.02223353 ... 0.0231483  0.02207901 0.02351354]\n",
      "  [0.02097395 0.02279555 0.02376533 ... 0.02270956 0.02322488 0.02293076]\n",
      "  [0.0222598  0.02205416 0.02210595 ... 0.02219017 0.02067645 0.02202351]]\n",
      "\n",
      " [[0.02281752 0.02323251 0.02274826 ... 0.02295719 0.02330608 0.02297578]\n",
      "  [0.0209754  0.02345003 0.02134929 ... 0.02161308 0.02197118 0.02294771]\n",
      "  [0.02140538 0.01983954 0.02200707 ... 0.02379593 0.021716   0.02196138]]]\n",
      "NumPy - gamma (scalar): 0.01781221\n",
      "NumPy - centered (reshaped - gamma):\n",
      "[[[0.00451308 0.00575217 0.00442132 ... 0.00533609 0.0042668  0.00570134]\n",
      "  [0.00316174 0.00498334 0.00595312 ... 0.00489735 0.00541267 0.00511855]\n",
      "  [0.00444759 0.00424195 0.00429374 ... 0.00437796 0.00286424 0.0042113 ]]\n",
      "\n",
      " [[0.00500531 0.0054203  0.00493605 ... 0.00514499 0.00549387 0.00516357]\n",
      "  [0.00316319 0.00563782 0.00353708 ... 0.00380087 0.00415897 0.0051355 ]\n",
      "  [0.00359317 0.00202733 0.00419486 ... 0.00598372 0.00390379 0.00414917]]]\n",
      "NumPy - x_pow (centered ^ 10.0):\n",
      "[[[3.50533578e-24 3.96567824e-23 2.85440542e-24 ... 1.87169572e-23\n",
      "   1.99996888e-24 3.62882233e-23]\n",
      "  [9.98293800e-26 9.44509552e-24 5.59048053e-23 ... 7.93612530e-24\n",
      "   2.15831776e-23 1.23443589e-23]\n",
      "  [3.02866776e-24 1.88648118e-24 2.12990867e-24 ... 2.58655007e-24\n",
      "   3.71617766e-26 1.75452270e-24]]\n",
      "\n",
      " [[9.86993025e-24 2.18895648e-23 8.58613485e-24 ... 1.29969504e-23\n",
      "   2.50484495e-23 1.34740535e-23]\n",
      "  [1.00288466e-25 3.24423780e-23 3.06517205e-25 ... 6.29267639e-25\n",
      "   1.54830972e-24 1.27593802e-23]\n",
      "  [3.58742952e-25 1.17284993e-27 1.68723681e-24 ... 5.88453758e-23\n",
      "   8.21981033e-25 1.51221283e-24]]]\n",
      "NumPy - pooled (mean over aug):\n",
      "[[2.2112775e-24 1.6996120e-23 2.0296373e-23 ... 9.7465437e-24\n",
      "  7.8734361e-24 1.6795701e-23]\n",
      " [3.4429874e-24 1.8111039e-23 3.5266299e-24 ... 2.4157198e-23\n",
      "  9.1395792e-24 9.2485485e-24]]\n",
      "NumPy - root (pooled ^ (1/10.0)): \n",
      "[[0.00430987 0.00528488 0.0053795  ... 0.00499902 0.00489346 0.00527861]\n",
      " [0.00450499 0.00531856 0.00451581 ... 0.005474   0.00496698 0.00497287]]\n",
      "NumPy - output (root + gamma):\n",
      "[[0.02212208 0.02309709 0.02319171 ... 0.02281123 0.02270567 0.02309082]\n",
      " [0.0223172  0.02313077 0.02232802 ... 0.02328621 0.02277919 0.02278508]]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar versión NumPy\n",
    "print(\"\\n=== NumPy SGEM Debug ===\")\n",
    "sgem_out_np = sgem_fusion_numpy(pooled_norm_old, aug=aug, p=10.0, eps=1e-8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
