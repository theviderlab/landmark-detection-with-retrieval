{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f375db5f-d9c8-4837-9f80-6b198b422cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmark_detection.pipeline import Pipeline_Landmark_Detection\n",
    "from benchmark.revisitop.dataset import configdataset\n",
    "from benchmark.evaluation import run_evaluation2, save_evaluation_result\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844d9b9a-abd4-44a3-8d87-641d6be5c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 0\n",
    "\n",
    "force_rebuild = True\n",
    "save_every = 500\n",
    "config = {\n",
    "    'version': VERSION,\n",
    "    \n",
    "    # DATABASE\n",
    "    'min_area': 0.0,\n",
    "    'min_sim_db': 0.0,\n",
    "    \n",
    "    # PIPELINE\n",
    "    'detector_file': \"yolov8n-oiv7.pt\",\n",
    "    'extractor_onnx_file': \"cvnet-sg-v\" + str(VERSION) + \".onnx\",\n",
    "    'pipeline_onnx_file': \"pipeline-yolo-cvnet-sg-v\" + str(VERSION) + \".onnx\",\n",
    "    'image_dim': (640, 640),\n",
    "    'allowed_classes': [41,68,70,74,87,95,113,144,150,158,164,165,193,205,212,224,257,\n",
    "                                  298,310,335,351,354,390,393,401,403,439,442,457,466,489,510,512,\n",
    "                                  514,524,530,531,543,546,554,565,573,580,588,591],\n",
    "    'score_thresh': 0.05,\n",
    "    'iou_thresh': 0.25,\n",
    "    'scales': [0.7071, 1.0, 1.4142],\n",
    "    'mean': [0.485, 0.456, 0.406],\n",
    "    'std': [0.229, 0.224, 0.225],\n",
    "    'rgem_pr': 2.5,\n",
    "    'rgem_size': 5,\n",
    "    'gem_p': 4.6,\n",
    "    'sgem_ps': 10.0,\n",
    "    'sgem_infinity': False,\n",
    "    'eps': 1e-8,\n",
    "}\n",
    "topk = 10\n",
    "min_sim = 0.70\n",
    "min_votes = 0.60\n",
    "remove_inner_boxes = 0.5\n",
    "join_boxes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47860aec-f873-4c73-97ea-6efe19158e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Paths\n",
    "CLASS_NAMES_PATH = os.path.join(\"oiv7.yaml\")\n",
    "DATASETS_PATH = os.path.abspath(\"datasets\")\n",
    "ROXFORD5K_PATH = os.path.join(DATASETS_PATH, \"roxford5k\", \"jpg\")\n",
    "ROXFORD5K_PKL = os.path.join(DATASETS_PATH, \"roxford5k\", \"gnd_roxford5k.pkl\")\n",
    "ROXFORD5K_CSV = os.path.join(DATASETS_PATH, \"roxford5k\", \"roxford5k_image_data.csv\")\n",
    "RESULTS_PATH = os.path.join(\"benchmark\", \"results\", \"results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21737ac-b65c-4b1f-a6a0-5fe8b09a581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = configdataset('roxford5k', DATASETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57814ef4-6954-4f0f-b631-1acc30487b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_CONFIG_PATH = os.path.join(\"configs\", \"pipeline-yolo-cvnet-sg-v\" + str(VERSION))\n",
    "\n",
    "# Dataset Oxford\n",
    "ROXFORD5K_DF = os.path.join(DATASETS_PATH, \"roxford5k\", \"results\", \"df_roxford5k-v\" + str(VERSION) + \".pkl\")\n",
    "ROXFORD5K_DESC = os.path.join(DATASETS_PATH, \"roxford5k\", \"results\", \"desc_roxford5k-v\" + str(VERSION) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13727274-5ab4-4d23-9a5f-e0407e5762a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando versión ONNX del preprocess\n",
      "Instanciando el preprocessor\n",
      "Creando versión ONNX del detector\n",
      "Ultralytics 8.3.146  Python-3.11.11 torch-2.7.0+cpu CPU (Intel Core(TM) i5-9300HF 2.40GHz)\n",
      "YOLOv8n summary (fused): 72 layers, 3,492,527 parameters, 0 gradients, 10.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 605, 8400) (6.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 16...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.54...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.5s, saved as 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx' (13.5 MB)\n",
      "\n",
      "Export complete (2.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/open-images-v7.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Instanciando el detector\n",
      "Creando versión ONNX del extractor\n",
      "Instanciando el extractor\n",
      "Creando versión ONNX del searcher\n",
      "Instanciando el searcher\n",
      "Creando versión ONNX del postprocess\n",
      "Instanciando el postprocessor\n",
      "Creando versión ONNX del pipeline completo\n",
      "Instanciando el pipeline completo\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline_Landmark_Detection(\n",
    "        detector_file = config['detector_file'],\n",
    "        extractor_onnx_file = config['extractor_onnx_file'],\n",
    "        pipeline_onnx_file = config['pipeline_onnx_file'],\n",
    "        image_dim = config['image_dim'],\n",
    "        allowed_classes = config['allowed_classes'],\n",
    "        score_thresh = config['score_thresh'],\n",
    "        iou_thresh = config['iou_thresh'],\n",
    "        scales = config['scales'],\n",
    "        mean = config['mean'],\n",
    "        std = config['std'],\n",
    "        rgem_pr = config['rgem_pr'],\n",
    "        rgem_size = config['rgem_size'],\n",
    "        gem_p = config['gem_p'],\n",
    "        sgem_ps = config['sgem_ps'],\n",
    "        sgem_infinity = config['sgem_infinity'],\n",
    "        eps = config['eps'],\n",
    "        topk = topk,\n",
    "        min_sim = min_sim,\n",
    "        min_votes = min_votes,\n",
    "        remove_inner_boxes = remove_inner_boxes,\n",
    "        join_boxes = join_boxes\n",
    ")\n",
    "pipeline.to_json(PIPELINE_CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed32c84-0302-4616-8bf0-c61da85bfb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5063/5063 [1:03:08<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build/load roxford5k dataset\n",
    "df_result_ox, descriptors_final_ox, places_db_ox = pipeline.build_image_database(\n",
    "    image_folder = ROXFORD5K_PATH,\n",
    "    df_pickle_path = ROXFORD5K_DF,\n",
    "    descriptor_pickle_path = ROXFORD5K_DESC,\n",
    "    return_places_db = True,\n",
    "    force_rebuild = force_rebuild,\n",
    "    save_every = save_every,\n",
    "    min_area = config['min_area'],\n",
    "    min_sim = config['min_sim_db']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47ab4d93-0e8c-4183-95ea-63b097d299e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> roxford5k: Evaluating test dataset...\n",
      ">> roxford5k: Loading features...\n",
      ">> roxford5k: Retrieval...\n",
      ">> roxford5k: mAP E: 75.49, M: 58.69, H: 30.34\n",
      ">> roxford5k: mP@k[ 1  5 10] E: [      97.06       84.04       78.46], M: [      95.71       81.81       77.19], H: [      64.29       53.43       44.14]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate roxford5k\n",
    "roxford5k_eval = run_evaluation2(df_result_ox, places_db_ox, 'roxford5k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9eb9d00-a143-4beb-aa8e-844ebd047b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> roxford5k: Evaluating test dataset...\n",
      ">> roxford5k: Loading features...\n",
      ">> roxford5k: Retrieval...\n",
      ">> roxford5k: mAP E: 70.87, M: 54.89, H: 26.25\n",
      ">> roxford5k: mP@k[ 1  5 10] E: [      92.65       81.99       77.62], M: [         90       75.52       72.57], H: [      65.71       46.43       39.12]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate roxford5k with bbox\n",
    "roxford5k_eval_bbox = run_evaluation2(df_result_ox, places_db_ox, 'roxford5k', use_bbox=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c224c84f-6190-4e20-8262-f7bd9fc57ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map_easy': np.float64(0.7548713229454185),\n",
       " 'map_medium': np.float64(0.5868571475011939),\n",
       " 'map_hard': np.float64(0.3034443151332889),\n",
       " 'mpr_easy': array([    0.97059,     0.84044,     0.78456]),\n",
       " 'mpr_medium': array([    0.95714,      0.8181,      0.7719]),\n",
       " 'mpr_hard': array([    0.64286,     0.53429,     0.44143])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roxford5k_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d26ffb5-540a-40a6-ae83-c541de919bf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m save_evaluation_result(roxford5k_eval, roxford5k_eval_bbox, RESULTS_PATH, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\landmark-detection-with-retrieval\\benchmark\\evaluation.py:460\u001b[39m, in \u001b[36msave_evaluation_result\u001b[39m\u001b[34m(results, results_bbox, path, config)\u001b[39m\n\u001b[32m    458\u001b[39m data.append({\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m: results, \u001b[33m\"\u001b[39m\u001b[33mresults_bbox\u001b[39m\u001b[33m\"\u001b[39m: results_bbox, \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m: config})\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     json.dump(data, f, indent=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\envs\\tfm_yolo\\Lib\\json\\__init__.py:179\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    173\u001b[39m     iterable = \u001b[38;5;28mcls\u001b[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    174\u001b[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    175\u001b[39m         separators=separators,\n\u001b[32m    176\u001b[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[32m    180\u001b[39m     fp.write(chunk)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\envs\\tfm_yolo\\Lib\\json\\encoder.py:430\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\envs\\tfm_yolo\\Lib\\json\\encoder.py:326\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_list\u001b[39m\u001b[34m(lst, _current_indent_level)\u001b[39m\n\u001b[32m    324\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    325\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    328\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\envs\\tfm_yolo\\Lib\\json\\encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\envs\\tfm_yolo\\Lib\\json\\encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\envs\\tfm_yolo\\Lib\\json\\encoder.py:439\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    437\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCircular reference detected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    438\u001b[39m     markers[markerid] = o\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m o = _default(o)\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\envs\\tfm_yolo\\Lib\\json\\encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "save_evaluation_result(roxford5k_eval, roxford5k_eval_bbox, RESULTS_PATH, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
