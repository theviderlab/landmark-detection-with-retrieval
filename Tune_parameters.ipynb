{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f375db5f-d9c8-4837-9f80-6b198b422cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmark_detection.pipeline import Pipeline_Landmark_Detection\n",
    "from benchmark.revisitop.dataset import configdataset\n",
    "from benchmark.evaluation import run_evaluation2, save_evaluation_result\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "844d9b9a-abd4-44a3-8d87-641d6be5c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 0\n",
    "\n",
    "force_rebuild = False\n",
    "save_every = 500\n",
    "config = {\n",
    "    'version': VERSION,\n",
    "    \n",
    "    # DATABASE\n",
    "    'min_area': 0.4,\n",
    "    'min_sim_db': 0.9,\n",
    "    'keep_full_img': True,\n",
    "    \n",
    "    # PIPELINE\n",
    "    'detector_file': \"yolov8n-oiv7.pt\",\n",
    "    'extractor_onnx_file': \"cvnet-sg-v\" + str(VERSION) + \".onnx\",\n",
    "    'pipeline_onnx_file': \"pipeline-yolo-cvnet-sg-v\" + str(VERSION) + \".onnx\",\n",
    "    'image_dim': (640, 640),\n",
    "    'allowed_classes': [41,68,70,74,87,95,113,144,150,158,164,165,193,205,212,224,257,\n",
    "                                  298,310,335,351,354,390,393,401,403,439,442,457,466,489,510,512,\n",
    "                                  514,524,530,531,543,546,554,565,573,580,588,591],\n",
    "    'score_thresh': 0.05,\n",
    "    'iou_thresh': 0.4,\n",
    "    'scales': [0.7071, 1.0, 1.4142],\n",
    "    'mean': [0.485, 0.456, 0.406],\n",
    "    'std': [0.229, 0.224, 0.225],\n",
    "    'rgem_pr': 2.5,\n",
    "    'rgem_size': 5,\n",
    "    'gem_p': 4.6,\n",
    "    'sgem_ps': 10.0,\n",
    "    'sgem_infinity': False,\n",
    "    'eps': 1e-8,\n",
    "}\n",
    "topk = 10\n",
    "min_sim = 0.70\n",
    "min_votes = 0.60\n",
    "remove_inner_boxes = 0.5\n",
    "join_boxes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47860aec-f873-4c73-97ea-6efe19158e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Paths\n",
    "CLASS_NAMES_PATH = os.path.join(\"oiv7.yaml\")\n",
    "DATASETS_PATH = os.path.abspath(\"datasets\")\n",
    "dataset = \"rparis6k\" # \"roxford5k\"\n",
    "ROXFORD5K_PATH = os.path.join(DATASETS_PATH, dataset, \"jpg\")\n",
    "ROXFORD5K_PKL = os.path.join(DATASETS_PATH, dataset, \"gnd_roxford5k.pkl\")\n",
    "ROXFORD5K_CSV = os.path.join(DATASETS_PATH, dataset, \"roxford5k_image_data.csv\")\n",
    "RESULTS_PATH = os.path.join(\"benchmark\", \"results\", \"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b21737ac-b65c-4b1f-a6a0-5fe8b09a581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = configdataset(dataset, DATASETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13727274-5ab4-4d23-9a5f-e0407e5762a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando versión ONNX del preprocess\n",
      "Instanciando el preprocessor\n",
      "Creando versión ONNX del detector\n",
      "Ultralytics 8.3.146  Python-3.11.11 torch-2.7.0+cpu CPU (Intel Core(TM) i5-9300HF 2.40GHz)\n",
      "YOLOv8n summary (fused): 72 layers, 3,492,527 parameters, 0 gradients, 10.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 605, 8400) (6.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 16...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.54...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.4s, saved as 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx' (13.5 MB)\n",
      "\n",
      "Export complete (3.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/open-images-v7.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Instanciando el detector\n",
      "Creando versión ONNX del extractor\n",
      "Instanciando el extractor\n",
      "Creando versión ONNX del searcher\n",
      "Instanciando el searcher\n",
      "Creando versión ONNX del postprocess\n",
      "Instanciando el postprocessor\n",
      "Creando versión ONNX del pipeline completo\n",
      "Instanciando el pipeline completo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6392/6392 [1:49:33<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.06, M: 76.52, H: 54.87\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      97.14       94.95       93.24], M: [      98.57       97.71       97.29], H: [      92.86       92.29          89]\n",
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.42, M: 76.59, H: 55.11\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      98.57       95.71       93.43], M: [      98.57          98          97], H: [      92.86       92.86          90]\n",
      "Creando versión ONNX del preprocess\n",
      "Instanciando el preprocessor\n",
      "Creando versión ONNX del detector\n",
      "Ultralytics 8.3.146  Python-3.11.11 torch-2.7.0+cpu CPU (Intel Core(TM) i5-9300HF 2.40GHz)\n",
      "YOLOv8n summary (fused): 72 layers, 3,492,527 parameters, 0 gradients, 10.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 605, 8400) (6.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 16...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.54...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.9s, saved as 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx' (13.5 MB)\n",
      "\n",
      "Export complete (4.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/open-images-v7.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Instanciando el detector\n",
      "Creando versión ONNX del extractor\n",
      "Instanciando el extractor\n",
      "Creando versión ONNX del searcher\n",
      "Instanciando el searcher\n",
      "Creando versión ONNX del postprocess\n",
      "Instanciando el postprocessor\n",
      "Creando versión ONNX del pipeline completo\n",
      "Instanciando el pipeline completo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6392/6392 [1:55:19<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.06, M: 76.52, H: 54.87\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      97.14       94.95       93.24], M: [      98.57       97.71       97.29], H: [      92.86       92.29          89]\n",
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.42, M: 76.59, H: 55.11\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      98.57       95.71       93.43], M: [      98.57          98          97], H: [      92.86       92.86          90]\n",
      "Creando versión ONNX del preprocess\n",
      "Instanciando el preprocessor\n",
      "Creando versión ONNX del detector\n",
      "Ultralytics 8.3.146  Python-3.11.11 torch-2.7.0+cpu CPU (Intel Core(TM) i5-9300HF 2.40GHz)\n",
      "YOLOv8n summary (fused): 72 layers, 3,492,527 parameters, 0 gradients, 10.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 605, 8400) (6.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 16...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.54...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.5s, saved as 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx' (13.5 MB)\n",
      "\n",
      "Export complete (3.6s)\n",
      "Results saved to \u001b[1mC:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/open-images-v7.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Instanciando el detector\n",
      "Creando versión ONNX del extractor\n",
      "Instanciando el extractor\n",
      "Creando versión ONNX del searcher\n",
      "Instanciando el searcher\n",
      "Creando versión ONNX del postprocess\n",
      "Instanciando el postprocessor\n",
      "Creando versión ONNX del pipeline completo\n",
      "Instanciando el pipeline completo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6392/6392 [1:45:41<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.13, M: 76.62, H: 55.02\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      97.14       94.95       93.24], M: [      98.57       97.71       97.29], H: [      92.86       92.29       89.14]\n",
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.52, M: 76.69, H: 55.27\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      98.57       95.71       93.43], M: [      98.57          98          97], H: [      92.86       92.86       89.86]\n",
      "Creando versión ONNX del preprocess\n",
      "Instanciando el preprocessor\n",
      "Creando versión ONNX del detector\n",
      "Ultralytics 8.3.146  Python-3.11.11 torch-2.7.0+cpu CPU (Intel Core(TM) i5-9300HF 2.40GHz)\n",
      "YOLOv8n summary (fused): 72 layers, 3,492,527 parameters, 0 gradients, 10.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 605, 8400) (6.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 16...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.54...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  6.0s, saved as 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx' (13.5 MB)\n",
      "\n",
      "Export complete (7.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/open-images-v7.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Instanciando el detector\n",
      "Creando versión ONNX del extractor\n",
      "Instanciando el extractor\n",
      "Creando versión ONNX del searcher\n",
      "Instanciando el searcher\n",
      "Creando versión ONNX del postprocess\n",
      "Instanciando el postprocessor\n",
      "Creando versión ONNX del pipeline completo\n",
      "Instanciando el pipeline completo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6392/6392 [1:45:56<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.09, M: 76.55, H: 54.92\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      97.14       94.95       93.24], M: [      98.57       97.71       97.29], H: [      92.86       92.29          89]\n",
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.45, M: 76.63, H: 55.18\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      98.57       95.71       93.43], M: [      98.57          98          97], H: [      92.86       92.86          90]\n",
      "Creando versión ONNX del preprocess\n",
      "Instanciando el preprocessor\n",
      "Creando versión ONNX del detector\n",
      "Ultralytics 8.3.146  Python-3.11.11 torch-2.7.0+cpu CPU (Intel Core(TM) i5-9300HF 2.40GHz)\n",
      "YOLOv8n summary (fused): 72 layers, 3,492,527 parameters, 0 gradients, 10.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 605, 8400) (6.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 16...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.54...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.7s, saved as 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx' (13.5 MB)\n",
      "\n",
      "Export complete (3.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/open-images-v7.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Instanciando el detector\n",
      "Creando versión ONNX del extractor\n",
      "Instanciando el extractor\n",
      "Creando versión ONNX del searcher\n",
      "Instanciando el searcher\n",
      "Creando versión ONNX del postprocess\n",
      "Instanciando el postprocessor\n",
      "Creando versión ONNX del pipeline completo\n",
      "Instanciando el pipeline completo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6392/6392 [1:46:21<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.07, M: 76.54, H: 54.9\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      97.14       94.95       93.24], M: [      98.57       97.71       97.29], H: [      92.86       92.29          89]\n",
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.44, M: 76.61, H: 55.16\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      98.57       95.71       93.43], M: [      98.57          98          97], H: [      92.86       92.86          90]\n",
      "Creando versión ONNX del preprocess\n",
      "Instanciando el preprocessor\n",
      "Creando versión ONNX del detector\n",
      "Ultralytics 8.3.146  Python-3.11.11 torch-2.7.0+cpu CPU (Intel Core(TM) i5-9300HF 2.40GHz)\n",
      "YOLOv8n summary (fused): 72 layers, 3,492,527 parameters, 0 gradients, 10.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 605, 8400) (6.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 16...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.54...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.7s, saved as 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx' (13.5 MB)\n",
      "\n",
      "Export complete (3.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/open-images-v7.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Instanciando el detector\n",
      "Creando versión ONNX del extractor\n",
      "Instanciando el extractor\n",
      "Creando versión ONNX del searcher\n",
      "Instanciando el searcher\n",
      "Creando versión ONNX del postprocess\n",
      "Instanciando el postprocessor\n",
      "Creando versión ONNX del pipeline completo\n",
      "Instanciando el pipeline completo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6392/6392 [1:45:39<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.26, M: 76.7, H: 55.12\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      97.14       94.95       93.38], M: [      98.57       97.43          97], H: [      92.86       92.29       89.43]\n",
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.6, M: 76.79, H: 55.43\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      98.57       95.71       93.43], M: [      98.57          98          97], H: [      92.86       92.86       89.86]\n",
      "Creando versión ONNX del preprocess\n",
      "Instanciando el preprocessor\n",
      "Creando versión ONNX del detector\n",
      "Ultralytics 8.3.146  Python-3.11.11 torch-2.7.0+cpu CPU (Intel Core(TM) i5-9300HF 2.40GHz)\n",
      "YOLOv8n summary (fused): 72 layers, 3,492,527 parameters, 0 gradients, 10.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 605, 8400) (6.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 16...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.54...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.8s, saved as 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx' (13.5 MB)\n",
      "\n",
      "Export complete (3.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/open-images-v7.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Instanciando el detector\n",
      "Creando versión ONNX del extractor\n",
      "Instanciando el extractor\n",
      "Creando versión ONNX del searcher\n",
      "Instanciando el searcher\n",
      "Creando versión ONNX del postprocess\n",
      "Instanciando el postprocessor\n",
      "Creando versión ONNX del pipeline completo\n",
      "Instanciando el pipeline completo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6392/6392 [1:36:30<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.15, M: 76.64, H: 55.05\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      97.14       94.95       93.38], M: [      98.57       97.71       97.29], H: [      92.86       92.29       89.29]\n",
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.54, M: 76.73, H: 55.36\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      98.57       95.71       93.43], M: [        100          98          97], H: [      94.29       92.86          90]\n",
      "Creando versión ONNX del preprocess\n",
      "Instanciando el preprocessor\n",
      "Creando versión ONNX del detector\n",
      "Ultralytics 8.3.146  Python-3.11.11 torch-2.7.0+cpu CPU (Intel Core(TM) i5-9300HF 2.40GHz)\n",
      "YOLOv8n summary (fused): 72 layers, 3,492,527 parameters, 0 gradients, 10.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 605, 8400) (6.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 16...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.54...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  7.2s, saved as 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx' (13.5 MB)\n",
      "\n",
      "Export complete (8.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/open-images-v7.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Instanciando el detector\n",
      "Creando versión ONNX del extractor\n",
      "Instanciando el extractor\n",
      "Creando versión ONNX del searcher\n",
      "Instanciando el searcher\n",
      "Creando versión ONNX del postprocess\n",
      "Instanciando el postprocessor\n",
      "Creando versión ONNX del pipeline completo\n",
      "Instanciando el pipeline completo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6392/6392 [1:42:35<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.12, M: 76.61, H: 55.01\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      97.14       94.95       93.38], M: [      98.57       97.71       97.14], H: [      92.86       92.29       89.29]\n",
      ">> rparis6k: Evaluating test dataset...\n",
      ">> rparis6k: Loading features...\n",
      ">> rparis6k: Retrieval...\n",
      ">> rparis6k: mAP E: 88.5, M: 76.7, H: 55.31\n",
      ">> rparis6k: mP@k[ 1  5 10] E: [      98.57       95.71       93.43], M: [      98.57          98          97], H: [      92.86       92.86          90]\n",
      "Creando versión ONNX del preprocess\n",
      "Instanciando el preprocessor\n",
      "Creando versión ONNX del detector\n",
      "Ultralytics 8.3.146  Python-3.11.11 torch-2.7.0+cpu CPU (Intel Core(TM) i5-9300HF 2.40GHz)\n",
      "YOLOv8n summary (fused): 72 layers, 3,492,527 parameters, 0 gradients, 10.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 605, 8400) (6.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 16...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.54...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  5.7s, saved as 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx' (13.5 MB)\n",
      "\n",
      "Export complete (7.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/open-images-v7.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Instanciando el detector\n",
      "Creando versión ONNX del extractor\n",
      "Instanciando el extractor\n",
      "Creando versión ONNX del searcher\n",
      "Instanciando el searcher\n",
      "Creando versión ONNX del postprocess\n",
      "Instanciando el postprocessor\n",
      "Creando versión ONNX del pipeline completo\n",
      "Instanciando el pipeline completo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   2%|███▏                                                                                                                                               | 137/6392 [04:48<7:16:39,  4.19s/it]"
     ]
    }
   ],
   "source": [
    "first_version = 72\n",
    "rgem_list = [\n",
    "    (0.5, 5), (0.5, 7), \n",
    "    (1.0, 3), (1.0, 5), (1.0, 7),  \n",
    "    (2.0, 3), (2.0, 5), (2.0, 7),  \n",
    "    (2.5, 3), (2.5, 7), \n",
    "    (3.0, 3), (3.0, 5), (3.0, 7),  \n",
    "    (3.5, 3), (3.5, 5), (3.5, 7),  \n",
    "    (4.0, 3), (4.0, 5), (4.0, 7),  \n",
    "]\n",
    "for i, (rgem_pr, rgem_size) in enumerate(rgem_list):\n",
    "    # Alter config\n",
    "    version = first_version + i\n",
    "    config['rgem_pr'] = rgem_pr\n",
    "    config['rgem_size'] = rgem_size\n",
    "    config['version'] = version\n",
    "    config['extractor_onnx_file'] = \"cvnet-sg-v\" + str(version) + \".onnx\"\n",
    "    config['pipeline_onnx_file'] = \"pipeline-yolo-cvnet-sg-v\" + str(version) + \".onnx\"    \n",
    "    PIPELINE_CONFIG_PATH = os.path.join(\"configs\", \"pipeline-yolo-cvnet-sg-v\" + str(version))\n",
    "    ROXFORD5K_DF = os.path.join(DATASETS_PATH, dataset, \"results\", \"df_\" + dataset + \"-v\" + str(version) + \".pkl\")\n",
    "    ROXFORD5K_DESC = os.path.join(DATASETS_PATH, dataset, \"results\", \"desc_\" + dataset + \"-v\" + str(version) + \".pkl\")\n",
    "\n",
    "    pipeline = Pipeline_Landmark_Detection(\n",
    "            detector_file = config['detector_file'],\n",
    "            extractor_onnx_file = config['extractor_onnx_file'],\n",
    "            pipeline_onnx_file = config['pipeline_onnx_file'],\n",
    "            image_dim = config['image_dim'],\n",
    "            allowed_classes = config['allowed_classes'],\n",
    "            score_thresh = config['score_thresh'],\n",
    "            iou_thresh = config['iou_thresh'],\n",
    "            scales = config['scales'],\n",
    "            mean = config['mean'],\n",
    "            std = config['std'],\n",
    "            rgem_pr = config['rgem_pr'],\n",
    "            rgem_size = config['rgem_size'],\n",
    "            gem_p = config['gem_p'],\n",
    "            sgem_ps = config['sgem_ps'],\n",
    "            sgem_infinity = config['sgem_infinity'],\n",
    "            eps = config['eps'],\n",
    "            topk = topk,\n",
    "            min_sim = min_sim,\n",
    "            min_votes = min_votes,\n",
    "            remove_inner_boxes = remove_inner_boxes,\n",
    "            join_boxes = join_boxes\n",
    "    )\n",
    "    pipeline.to_json(PIPELINE_CONFIG_PATH)\n",
    "    \n",
    "    # Build/load roxford5k dataset\n",
    "    df_result_ox, descriptors_final_ox, places_db_ox = pipeline.build_image_database(\n",
    "        image_folder = ROXFORD5K_PATH,\n",
    "        df_pickle_path = ROXFORD5K_DF,\n",
    "        descriptor_pickle_path = ROXFORD5K_DESC,\n",
    "        return_places_db = True,\n",
    "        force_rebuild = force_rebuild,\n",
    "        save_every = save_every,\n",
    "        min_area = config['min_area'],\n",
    "        min_sim = config['min_sim_db'],\n",
    "        keep_full_img = config['keep_full_img']\n",
    "    )\n",
    "    \n",
    "    # Evaluate roxford5k\n",
    "    roxford5k_eval = run_evaluation2(df_result_ox, places_db_ox, dataset)\n",
    "   \n",
    "    # Evaluate roxford5k with bbox\n",
    "    roxford5k_eval_bbox = run_evaluation2(df_result_ox, places_db_ox, dataset, use_bbox=True)\n",
    "    \n",
    "    results_eval = {\n",
    "        'map_easy': roxford5k_eval['map_easy']*100,\n",
    "        'mp@1_easy': roxford5k_eval['mpr_easy'][0]*100,\n",
    "        'mp@5_easy': roxford5k_eval['mpr_easy'][1]*100,\n",
    "        'mp@10_easy': roxford5k_eval['mpr_easy'][2]*100,\n",
    "        'map_medium': roxford5k_eval['map_medium']*100,\n",
    "        'mp@1_medium': roxford5k_eval['mpr_medium'][0]*100,\n",
    "        'mp@5_medium': roxford5k_eval['mpr_medium'][1]*100,\n",
    "        'mp@10_medium': roxford5k_eval['mpr_medium'][2]*100,\n",
    "        'map_hard': roxford5k_eval['map_hard']*100,\n",
    "        'mp@1_hard': roxford5k_eval['mpr_hard'][0]*100,\n",
    "        'mp@5_hard': roxford5k_eval['mpr_hard'][1]*100,\n",
    "        'mp@10_hard': roxford5k_eval['mpr_hard'][2]*100,\n",
    "        'map_easy_bbox': roxford5k_eval_bbox['map_easy']*100,\n",
    "        'mp@1_easy_bbox': roxford5k_eval_bbox['mpr_easy'][0]*100,\n",
    "        'mp@5_easy_bbox': roxford5k_eval_bbox['mpr_easy'][1]*100,\n",
    "        'mp@10_easy_bbox': roxford5k_eval_bbox['mpr_easy'][2]*100,\n",
    "        'map_medium_bbox': roxford5k_eval_bbox['map_medium']*100,\n",
    "        'mp@1_medium_bbox': roxford5k_eval_bbox['mpr_medium'][0]*100,\n",
    "        'mp@5_medium_bbox': roxford5k_eval_bbox['mpr_medium'][1]*100,\n",
    "        'mp@10_medium_bbox': roxford5k_eval_bbox['mpr_medium'][2]*100,\n",
    "        'map_hard_bbox': roxford5k_eval_bbox['map_hard']*100,\n",
    "        'mp@1_hard_bbox': roxford5k_eval_bbox['mpr_hard'][0]*100,\n",
    "        'mp@5_hard_bbox': roxford5k_eval_bbox['mpr_hard'][1]*100,\n",
    "        'mp@10_hard_bbox': roxford5k_eval_bbox['mpr_hard'][2]*100,\n",
    "        'inference_time': '',\n",
    "    }\n",
    "    results = {**config, **results_eval}\n",
    "    df = pd.DataFrame.from_dict([results])\n",
    "    \n",
    "    # Verificar si el archivo ya existe\n",
    "    if os.path.exists(RESULTS_PATH):\n",
    "        # Cargar el archivo existente\n",
    "        df_saved = pd.read_csv(RESULTS_PATH)\n",
    "    else:\n",
    "        # Crear un DataFrame vacío con las claves de la nueva fila\n",
    "        df_saved = pd.DataFrame(columns=df.keys())\n",
    "    \n",
    "    # Agregar la nueva fila\n",
    "    df_saved = pd.concat([df_saved, df], ignore_index=True)\n",
    "    \n",
    "    # Guardar el archivo actualizado\n",
    "    df_saved.to_csv(RESULTS_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
