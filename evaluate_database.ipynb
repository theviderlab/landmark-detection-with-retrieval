{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed69fa5-5442-4fa2-affa-aa1a5481875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmark_detection.pipeline import Pipeline_Yolo_CVNet_SG\n",
    "from benchmark.database import build_image_database\n",
    "from landmark_detection.utils import show_image, show_bboxes\n",
    "from benchmark.revisitop.evaluate import compute_map\n",
    "from benchmark.revisitop.dataset import configdataset\n",
    "from benchmark.evaluation import run_evaluation\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29017a2-f81c-4660-bce4-3e144a7381da",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4dd9da8-4bf4-4e0d-b64f-6fa623eabc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando versi贸n ONNX del detector\n",
      "Ultralytics 8.3.146  Python-3.11.11 torch-2.7.0+cpu CPU (Intel Core(TM) i5-9300HF 2.40GHz)\n",
      "YOLOv8n summary (fused): 72 layers, 3,492,527 parameters, 0 gradients, 10.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 605, 8400) (6.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 16...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.54...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.4s, saved as 'C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx' (13.5 MB)\n",
      "\n",
      "Export complete (3.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\rdiaz\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\models\\yolov8n-oiv7.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/open-images-v7.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Instanciando el detector\n",
      "Creando versi贸n ONNX del extractor\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pipeline = Pipeline_Yolo_CVNet_SG(\n\u001b[32m      2\u001b[39m         detector_file = \u001b[33m\"\u001b[39m\u001b[33myolov8n-oiv7.pt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m         extractor_onnx_file = \u001b[33m\"\u001b[39m\u001b[33mcvnet-sg-v\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(VERSION) + \u001b[33m\"\u001b[39m\u001b[33m.onnx\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m         pipeline_onnx_file = \u001b[33m\"\u001b[39m\u001b[33mpipeline-yolo-cvnet-sg-v\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(VERSION) + \u001b[33m\"\u001b[39m\u001b[33m.onnx\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m         image_dim = (\u001b[32m640\u001b[39m, \u001b[32m640\u001b[39m),\n\u001b[32m      6\u001b[39m         allowed_classes = [\u001b[32m41\u001b[39m,\u001b[32m68\u001b[39m,\u001b[32m70\u001b[39m,\u001b[32m74\u001b[39m,\u001b[32m87\u001b[39m,\u001b[32m95\u001b[39m,\u001b[32m113\u001b[39m,\u001b[32m144\u001b[39m,\u001b[32m150\u001b[39m,\u001b[32m158\u001b[39m,\u001b[32m164\u001b[39m,\u001b[32m165\u001b[39m,\u001b[32m193\u001b[39m,\u001b[32m205\u001b[39m,\u001b[32m212\u001b[39m,\u001b[32m224\u001b[39m,\u001b[32m257\u001b[39m,\n\u001b[32m      7\u001b[39m                                       \u001b[32m298\u001b[39m,\u001b[32m310\u001b[39m,\u001b[32m335\u001b[39m,\u001b[32m351\u001b[39m,\u001b[32m354\u001b[39m,\u001b[32m390\u001b[39m,\u001b[32m393\u001b[39m,\u001b[32m401\u001b[39m,\u001b[32m403\u001b[39m,\u001b[32m439\u001b[39m,\u001b[32m442\u001b[39m,\u001b[32m457\u001b[39m,\u001b[32m466\u001b[39m,\u001b[32m489\u001b[39m,\u001b[32m510\u001b[39m,\u001b[32m512\u001b[39m,\n\u001b[32m      8\u001b[39m                                       \u001b[32m514\u001b[39m,\u001b[32m524\u001b[39m,\u001b[32m530\u001b[39m,\u001b[32m531\u001b[39m,\u001b[32m543\u001b[39m,\u001b[32m546\u001b[39m,\u001b[32m554\u001b[39m,\u001b[32m565\u001b[39m,\u001b[32m573\u001b[39m,\u001b[32m580\u001b[39m,\u001b[32m587\u001b[39m,\u001b[32m588\u001b[39m,\u001b[32m591\u001b[39m],\n\u001b[32m      9\u001b[39m         score_thresh = \u001b[32m0.10\u001b[39m,\n\u001b[32m     10\u001b[39m         iou_thresh = \u001b[32m0.45\u001b[39m,\n\u001b[32m     11\u001b[39m         scales = [\u001b[32m0.7071\u001b[39m, \u001b[32m1.0\u001b[39m, \u001b[32m1.4142\u001b[39m],\n\u001b[32m     12\u001b[39m         mean = [\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m],\n\u001b[32m     13\u001b[39m         std  = [\u001b[32m0.229\u001b[39m, \u001b[32m0.224\u001b[39m, \u001b[32m0.225\u001b[39m],\n\u001b[32m     14\u001b[39m         rgem_pr = \u001b[32m2.5\u001b[39m,\n\u001b[32m     15\u001b[39m         rgem_size = \u001b[32m5\u001b[39m,\n\u001b[32m     16\u001b[39m         gem_p = \u001b[32m4.6\u001b[39m,\n\u001b[32m     17\u001b[39m         sgem_ps = \u001b[32m10.0\u001b[39m,\n\u001b[32m     18\u001b[39m         sgem_infinity = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     19\u001b[39m         eps = \u001b[32m1e-8\u001b[39m  \n\u001b[32m     20\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\pipeline.py:95\u001b[39m, in \u001b[36mPipeline_Yolo_CVNet_SG.__init__\u001b[39m\u001b[34m(self, detector_file, extractor_onnx_file, pipeline_onnx_file, image_dim, allowed_classes, score_thresh, iou_thresh, scales, mean, std, rgem_pr, rgem_size, gem_p, sgem_ps, sgem_infinity, eps)\u001b[39m\n\u001b[32m     93\u001b[39m test_image_path = os.path.join(module_dir, \u001b[33m\"\u001b[39m\u001b[33mtest_images\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtest.jpg\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mCreando versi贸n ONNX del extractor\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28mself\u001b[39m._export_extractor(extractor, extractor_onnx_path, test_image_path)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# Si no existe el archivo .onnx se crea\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isabs(pipeline_onnx_file) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pipeline_onnx_file):\n\u001b[32m     99\u001b[39m     \u001b[38;5;66;03m# Construir la ruta absoluta dentro de este m贸dulo\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\pipeline.py:213\u001b[39m, in \u001b[36mPipeline_Yolo_CVNet_SG._export_extractor\u001b[39m\u001b[34m(self, extractor, extractor_onnx_path, test_image_path)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_export_extractor\u001b[39m(\u001b[38;5;28mself\u001b[39m, extractor, extractor_onnx_path: \u001b[38;5;28mstr\u001b[39m, test_image_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     detections, img  = \u001b[38;5;28mself\u001b[39m.detect(test_image_path)\n\u001b[32m    215\u001b[39m     img_tensor = torch.from_numpy(img)\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(detections, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\pipeline.py:135\u001b[39m, in \u001b[36mPipeline_Yolo_CVNet_SG.detect\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[32m    133\u001b[39m \n\u001b[32m    134\u001b[39m     \u001b[38;5;66;03m# Preprocesar imagen\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     img, _ = \u001b[38;5;28mself\u001b[39m.preprocess(image)\n\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# Obtener detecciones\u001b[39;00m\n\u001b[32m    138\u001b[39m     input_name = \u001b[38;5;28mself\u001b[39m.detector.get_inputs()[\u001b[32m0\u001b[39m].name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\pipeline.py:303\u001b[39m, in \u001b[36mPipeline_Yolo_CVNet_SG.preprocess\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    301\u001b[39m     img_tensor = torch.as_tensor(image)\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m processed, orig_size = \u001b[38;5;28mself\u001b[39m.preprocess_module(img_tensor)\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m processed.numpy(), (\u001b[38;5;28mint\u001b[39m(orig_size[\u001b[32m0\u001b[39m]), \u001b[38;5;28mint\u001b[39m(orig_size[\u001b[32m1\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\envs\\tfm_yolo\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\envs\\tfm_yolo\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\landmark-detection-with-retrieval\\landmark_detection\\preprocess.py:18\u001b[39m, in \u001b[36mPreprocessModule.forward\u001b[39m\u001b[34m(self, img_bgr)\u001b[39m\n\u001b[32m     16\u001b[39m img_rgb = img_rgb[[\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m], ...]  \u001b[38;5;66;03m# BGR -> RGB\u001b[39;00m\n\u001b[32m     17\u001b[39m img_rgb = img_rgb.unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m img_resized = F.interpolate(\n\u001b[32m     19\u001b[39m     img_rgb,\n\u001b[32m     20\u001b[39m     size=\u001b[38;5;28mself\u001b[39m.image_dim,\n\u001b[32m     21\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mbilinear\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m     align_corners=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m img_norm = img_resized / \u001b[32m255.0\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m img_norm, orig_size\n",
      "\u001b[31mNameError\u001b[39m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline_Yolo_CVNet_SG(\n",
    "        detector_file = \"yolov8n-oiv7.pt\",\n",
    "        extractor_onnx_file = \"cvnet-sg-v\" + str(VERSION) + \".onnx\",\n",
    "        pipeline_onnx_file = \"pipeline-yolo-cvnet-sg-v\" + str(VERSION) + \".onnx\",\n",
    "        image_dim = (640, 640),\n",
    "        allowed_classes = [41,68,70,74,87,95,113,144,150,158,164,165,193,205,212,224,257,\n",
    "                                      298,310,335,351,354,390,393,401,403,439,442,457,466,489,510,512,\n",
    "                                      514,524,530,531,543,546,554,565,573,580,587,588,591],\n",
    "        score_thresh = 0.10,\n",
    "        iou_thresh = 0.45,\n",
    "        scales = [0.7071, 1.0, 1.4142],\n",
    "        mean = [0.485, 0.456, 0.406],\n",
    "        std  = [0.229, 0.224, 0.225],\n",
    "        rgem_pr = 2.5,\n",
    "        rgem_size = 5,\n",
    "        gem_p = 4.6,\n",
    "        sgem_ps = 10.0,\n",
    "        sgem_infinity = False,\n",
    "        eps = 1e-8  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35c793-f454-4c5f-af4d-9dfb3ee6204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "CLASS_NAMES_PATH = os.path.join(\"oiv7.yaml\")\n",
    "PIPELINE_CONFIG_PATH = os.path.join(\"configs\", \"pipeline-yolo-cvnet-sg-v\" + str(VERSION))\n",
    "DATASETS_PATH = os.path.abspath(\"datasets\")\n",
    "\n",
    "# Dataset Oxford\n",
    "ROXFORD5K_PATH = os.path.join(DATASETS_PATH, \"roxford5k\", \"jpg\")\n",
    "ROXFORD5K_PKL = os.path.join(DATASETS_PATH, \"roxford5k\", \"gnd_roxford5k.pkl\")\n",
    "ROXFORD5K_CSV = os.path.join(DATASETS_PATH, \"roxford5k\", \"roxford5k_image_data.csv\")\n",
    "ROXFORD5K_DF = os.path.join(DATASETS_PATH, \"roxford5k\", \"results\", \"df_roxford5k-v\" + str(VERSION) + \".pkl\")\n",
    "ROXFORD5K_DESC = os.path.join(DATASETS_PATH, \"roxford5k\", \"results\", \"desc_roxford5k-v\" + str(VERSION) + \".pkl\")\n",
    "\n",
    "# Dataset Paris\n",
    "RPARIS6K_PATH = os.path.join(DATASETS_PATH, \"rparis6k\", \"jpg\")\n",
    "RPARIS6K_PKL = os.path.join(DATASETS_PATH, \"rparis6k\", \"gnd_rparis6k.pkl\")\n",
    "RPARIS6K_CSV = os.path.join(DATASETS_PATH, \"rparis6k\", \"rparis6k_image_data.csv\")\n",
    "RPARIS6K_DF = os.path.join(DATASETS_PATH, \"rparis6k\", \"results\", \"df_rparis6k-v\" + str(VERSION) + \".pkl\")\n",
    "RPARIS6K_DESC = os.path.join(DATASETS_PATH, \"rparis6k\", \"results\", \"desc_rparis6k-v\" + str(VERSION) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e576817-2ce6-412c-9cfd-6f1c677af1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMG_PATH = os.path.join(\"test_images\", \"test.jpg\")\n",
    "final_boxes, final_scores, final_classes, descriptors = pipeline.run(TEST_IMG_PATH)\n",
    "show_bboxes(TEST_IMG_PATH, CLASS_NAMES_PATH, final_boxes, final_classes, final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f2f0d-ed73-4101-9c33-156a2fcd9a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.to_json(PIPELINE_CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8730813-203d-417d-8da2-204b2ef2f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build/load roxford5k dataset\n",
    "df_result, descriptors_final = build_image_database(\n",
    "    pipeline,\n",
    "    image_folder = ROXFORD5K_PATH,\n",
    "    df_pickle_path = ROXFORD5K_DF,\n",
    "    descriptor_pickle_path = ROXFORD5K_DESC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52e40d-3110-46a8-a37c-0a88f7df12c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate roxford5k\n",
    "roxford5k_eval = run_evaluation(df_result, descriptors_final, 'roxford5k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d8e3a0-80c5-4768-9541-61ea9f1eb6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate roxford5k\n",
    "roxford5k_eval = run_evaluation(df_result, descriptors_final, 'roxford5k', use_bbox=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ddc14b-c7d5-492a-98f1-9b07c2973573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build/load rparis6k dataset\n",
    "df_result, descriptors_final = build_image_database(\n",
    "    pipeline,\n",
    "    image_folder = RPARIS6K_PATH,\n",
    "    df_pickle_path = RPARIS6K_DF,\n",
    "    descriptor_pickle_path = RPARIS6K_DESC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254b56e-dc56-41a8-beae-6d0fcaca0e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate rparis6k\n",
    "rparis6k_eval = run_evaluation(df_result, descriptors_final, 'rparis6k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb390565-e80f-4c88-b646-16ab1567c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate rparis6k\n",
    "rparis6k_eval = run_evaluation(df_result, descriptors_final, 'rparis6k', use_bbox=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
