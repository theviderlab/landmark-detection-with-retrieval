{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79fa9d60-9f53-43db-9daa-7cf332860e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmark_detection.utils import load_image_database\n",
    "import os\n",
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "471a3c4e-e5dd-49a2-9238-d44c49fcc827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Ejecutando versión 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando v0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5063/5063 [1:04:35<00:00,  1.31img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️ Tiempo promedio por imagen (v0): 0.7163 segundos\n",
      "\n",
      "🔄 Ejecutando versión 198...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando v198: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6392/6392 [1:33:05<00:00,  1.14img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️ Tiempo promedio por imagen (v198): 0.8229 segundos\n",
      "\n",
      "🔄 Ejecutando versión 208...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando v208: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5063/5063 [1:06:07<00:00,  1.28img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️ Tiempo promedio por imagen (v208): 0.7320 segundos\n",
      "\n",
      "📊 Tiempos promedio por versión:\n",
      "  - Versión 0: 0.7163 s/img\n",
      "  - Versión 198: 0.8229 s/img\n",
      "  - Versión 208: 0.7320 s/img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "versions = [(0,'roxford5k'), (198,'rparis6k'), (208,'roxford5k')]\n",
    "avg_times_per_version = {}  # Guardamos los tiempos promedio aquí\n",
    "\n",
    "for (version, dataset) in versions:\n",
    "    print(f\"\\n🔄 Ejecutando versión {version}...\")\n",
    "\n",
    "    # Paths\n",
    "    PIPELINE_ONNX = os.path.join(\"landmark_detection\", \"models\", f\"pipeline-yolo-cvnet-sg-v{version}.onnx\")\n",
    "    RESULTS_PATH = os.path.join(\"datasets\", dataset, \"results\", f\"df_{dataset}-v{version}.pkl\")\n",
    "    DESCRIPTORS_PATH = os.path.join(\"datasets\", dataset, \"results\", f\"desc_{dataset}-v{version}.pkl\")\n",
    "    IMAGE_PATH = os.path.join(\"datasets\", dataset, \"jpg\")\n",
    "    \n",
    "    # Cargar modelo y datos\n",
    "    pipeline = ort.InferenceSession(PIPELINE_ONNX, providers=[\"CPUExecutionProvider\"])\n",
    "    df_result, descriptors_final, places_db = load_image_database(RESULTS_PATH, DESCRIPTORS_PATH)\n",
    "    image_names = df_result[df_result['class_id'] == -1]['image_name']\n",
    "    \n",
    "    # Convertir base de datos a numpy\n",
    "    if isinstance(places_db, torch.Tensor):\n",
    "        db_np = places_db.detach().cpu().numpy().astype(np.float32)\n",
    "    else:\n",
    "        db_np = np.asarray(places_db, dtype=np.float32)\n",
    "\n",
    "    # Procesar imágenes con barra de progreso\n",
    "    total_time = 0\n",
    "    for image_name in tqdm(image_names, desc=f\"Procesando v{version}\", unit=\"img\"):\n",
    "        image = os.path.join(IMAGE_PATH, image_name)\n",
    "        img_bgr = cv2.imread(image)\n",
    "        img_tensor = torch.as_tensor(img_bgr)\n",
    "\n",
    "        pipeline_inputs = {\n",
    "            pipeline.get_inputs()[0].name: img_tensor.numpy(),\n",
    "            pipeline.get_inputs()[1].name: db_np,\n",
    "        }\n",
    "\n",
    "        start = time.time()\n",
    "        pipeline.run(None, pipeline_inputs)\n",
    "        end = time.time()\n",
    "\n",
    "        total_time += end - start\n",
    "\n",
    "    avg_time = total_time / len(image_names)\n",
    "    avg_times_per_version[version] = avg_time\n",
    "    print(f\"⏱️ Tiempo promedio por imagen (v{version}): {avg_time:.4f} segundos\")\n",
    "\n",
    "# Mostrar todos los resultados\n",
    "print(\"\\n📊 Tiempos promedio por versión:\")\n",
    "for version, avg_time in avg_times_per_version.items():\n",
    "    print(f\"  - Versión {version}: {avg_time:.4f} s/img\")\n",
    "\n",
    "# Tiempo promedio por imagen (v223): 0.9822 segundos (inicial paris)\n",
    "# Tiempo promedio por imagen (v0): 0.7163 segundos (inicial oxford)\n",
    "# Tiempo promedio por imagen (v198): 0.8229 segundos (final paris)\n",
    "# Tiempo promedio por imagen (v208): 0.7320 segundos (final oxford)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
